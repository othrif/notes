{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Hyperparameter tunning for trees with GridSearch for Tree\"\n",
    "date: 2020-04-12T14:41:32+02:00\n",
    "author: \"Othmane Rifki\"\n",
    "type: technical_note\n",
    "draft: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problem: search for a set of optimal hyperparameters for a learning algorithm.\n",
    "- Solution: find a set of optimal hyperparameters that results in an optimal model.\n",
    "- Optimal model: yields an optimal score.\n",
    "- Score: in sklearn defaults to accuracy (classication) and $R^2$ (regression).\n",
    "- Cross validation is used to estimate the generalization performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Models\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "SEED=1\n",
    "\n",
    "# read csv into df\n",
    "df = pd.read_csv('liver/indian_liver_patient_preprocessed.csv')\n",
    "\n",
    "# Get features of interest and target labels\n",
    "X = df.iloc[:,:-1]\n",
    "y = (df.iloc[:,-1]).astype(int)\n",
    "\n",
    "# Split dataset into 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, \n",
    "                                                   test_size=0.2, \n",
    "                                                   stratify=y, \n",
    "                                                   random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of an untuned dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.540\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_proba = dt.predict_proba(X_test)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all hyperparameters of dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'presort': 'deprecated', 'random_state': 1, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# Instantiate dt\n",
    "dt = DecisionTreeClassifier(random_state=SEED)\n",
    "print(dt.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define search grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define params_dt\n",
    "params_dt = {'max_depth': [2,3,4],\n",
    "    'min_samples_leaf': [0.12,0.14,0.16,0.18]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for optimical tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GridSearchCV` with the `estimator` option becomes the new classifer, as if I have instantiated the estimator with the correct set of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyerparameters:\n",
      " {'max_depth': 3, 'min_samples_leaf': 0.12}\n",
      "Best CV accuracy: 0.729\n",
      "Test set ROC AUC score: 0.610\n"
     ]
    }
   ],
   "source": [
    "# Instantiate grid_dt\n",
    "grid_dt = GridSearchCV(estimator=dt,\n",
    "                       param_grid=params_dt,\n",
    "                       scoring='roc_auc',\n",
    "                       cv=5,\n",
    "                       n_jobs=-1)\n",
    "\n",
    "# Fit 'grid_dt' to the training data\n",
    "grid_dt.fit(X_train, y_train)\n",
    "\n",
    "# Extract best hyperparameters from 'grid_dt'\n",
    "best_hyperparams = grid_dt.best_params_\n",
    "print('Best hyerparameters:\\n', best_hyperparams)\n",
    "\n",
    "# Extract best CV score from 'grid_dt'\n",
    "best_CV_score = grid_dt.best_score_\n",
    "print('Best CV accuracy: {:.3f}'.format(best_CV_score))\n",
    "\n",
    "# Extract the best estimator\n",
    "best_model = grid_dt.best_estimator_\n",
    "\n",
    "# Predict the test set probabilities of the positive class\n",
    "y_pred_proba = grid_dt.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Compute test_roc_auc\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Print test_roc_auc\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the optimical tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set ROC AUC score: 0.610\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=3, min_samples_leaf=0.12, random_state=SEED)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_proba = dt.predict_proba(X_test)[:,1]\n",
    "test_roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print('Test set ROC AUC score: {:.3f}'.format(test_roc_auc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good improvement upon an untuned classification-tree would achieve a ROC AUC score of 0.54"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
